{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a563de42-4cc0-4401-b07f-4eea9313d9fa",
   "metadata": {},
   "source": [
    "**Code Cell 1** - Importing required libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec833b-1dc6-47d0-9cfa-563eab1e8600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:52:39.410944Z",
     "iopub.status.busy": "2025-03-06T00:52:39.410339Z",
     "iopub.status.idle": "2025-03-06T00:52:48.832533Z",
     "shell.execute_reply": "2025-03-06T00:52:48.831428Z",
     "shell.execute_reply.started": "2025-03-06T00:52:39.410918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3fs==2023.9.2 in /opt/conda/lib/python3.11/site-packages (2023.9.2)\n",
      "Requirement already satisfied: aiobotocore~=2.5.4 in /opt/conda/lib/python3.11/site-packages (from s3fs==2023.9.2) (2.5.4)\n",
      "Requirement already satisfied: fsspec==2023.9.2 in /opt/conda/lib/python3.11/site-packages (from s3fs==2023.9.2) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from s3fs==2023.9.2) (3.9.5)\n",
      "Collecting botocore<1.31.18,>=1.31.17 (from aiobotocore~=2.5.4->s3fs==2023.9.2)\n",
      "  Using cached botocore-1.31.17-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.11/site-packages (from aiobotocore~=2.5.4->s3fs==2023.9.2) (1.17.2)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore~=2.5.4->s3fs==2023.9.2) (0.12.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2023.9.2) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2023.9.2) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2023.9.2) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2023.9.2) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2023.9.2) (1.18.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs==2023.9.2) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs==2023.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs==2023.9.2) (1.26.19)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2023.9.2) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2023.9.2) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs==2023.9.2) (1.17.0)\n",
      "Using cached botocore-1.31.17-py3-none-any.whl (11.1 MB)\n",
      "Installing collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.162\n",
      "    Uninstalling botocore-1.34.162:\n",
      "      Successfully uninstalled botocore-1.34.162\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "amazon-sagemaker-sql-editor 0.1.15 requires aiobotocore<3,>=2.7.0, but you have aiobotocore 2.5.4 which is incompatible.\n",
      "amazon-sagemaker-sql-editor 0.1.15 requires botocore<2,>=1.31.64, but you have botocore 1.31.17 which is incompatible.\n",
      "boto3 1.34.162 requires botocore<1.35.0,>=1.34.162, but you have botocore 1.31.17 which is incompatible.\n",
      "s3transfer 0.10.4 requires botocore<2.0a.0,>=1.33.2, but you have botocore 1.31.17 which is incompatible.\n",
      "sagemaker-studio 1.0.9 requires botocore>=1.34.106, but you have botocore 1.31.17 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.31.17\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.34.162)\n",
      "Collecting botocore<1.35.0,>=1.34.162 (from boto3)\n",
      "  Using cached botocore-1.34.162-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.10.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.162->boto3) (1.17.0)\n",
      "Using cached botocore-1.34.162-py3-none-any.whl (12.5 MB)\n",
      "Installing collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.17\n",
      "    Uninstalling botocore-1.31.17:\n",
      "      Successfully uninstalled botocore-1.31.17\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "amazon-sagemaker-sql-editor 0.1.15 requires aiobotocore<3,>=2.7.0, but you have aiobotocore 2.5.4 which is incompatible.\n",
      "aiobotocore 2.5.4 requires botocore<1.31.18,>=1.31.17, but you have botocore 1.34.162 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.34.162\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IVS7do_HBzroiCiymNdxDg</td>\n",
       "      <td>fdFgZQQYQJeEAshH4lxSfQ</td>\n",
       "      <td>sGy67CpJctjeCWClWqonjA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>OK, the hype about having Hatch chili in your ...</td>\n",
       "      <td>1/27/2020 22:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QP2pSzSqpJTMWOCuUuyXkQ</td>\n",
       "      <td>JBLWSXBTKFvJYYiM-FnCOQ</td>\n",
       "      <td>3w7NRntdQ9h0KwDsksIt5Q</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pandemic pit stop to have an ice cream.... onl...</td>\n",
       "      <td>4/19/2020 5:33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oK0cGYStgDOusZKz9B1qug</td>\n",
       "      <td>2_9fKnXChUjC5xArfF8BLg</td>\n",
       "      <td>OMnPtRGmbY8qH_wIILfYKA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I was lucky enough to go to the soft opening a...</td>\n",
       "      <td>2/29/2020 19:43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E_ABvFCNVLbfOgRg3Pv1KQ</td>\n",
       "      <td>9MExTQ76GSKhxSWnTS901g</td>\n",
       "      <td>V9XlikTxq0My4gE8LULsjw</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I've gone to claim Jumpers all over the US and...</td>\n",
       "      <td>3/14/2020 21:47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rd222CrrnXkXukR2iWj69g</td>\n",
       "      <td>LPxuausjvDN88uPr-Q4cQA</td>\n",
       "      <td>CA5BOxKRDPGJgdUQ8OUOpw</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you haven't been  to Maynard's kitchen, it'...</td>\n",
       "      <td>1/17/2020 20:32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  IVS7do_HBzroiCiymNdxDg  fdFgZQQYQJeEAshH4lxSfQ  sGy67CpJctjeCWClWqonjA   \n",
       "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
       "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
       "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
       "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       1      1     0   \n",
       "1      5       1      1     1   \n",
       "2      5       1      0     0   \n",
       "3      5       0      0     0   \n",
       "4      4       1      0     0   \n",
       "\n",
       "                                                text             date  \\\n",
       "0  OK, the hype about having Hatch chili in your ...  1/27/2020 22:59   \n",
       "1  Pandemic pit stop to have an ice cream.... onl...   4/19/2020 5:33   \n",
       "2  I was lucky enough to go to the soft opening a...  2/29/2020 19:43   \n",
       "3  I've gone to claim Jumpers all over the US and...  3/14/2020 21:47   \n",
       "4  If you haven't been  to Maynard's kitchen, it'...  1/17/2020 20:32   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install s3fs==2023.9.2 \n",
    "!pip install boto3\n",
    "# importing the dataset\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "\n",
    "fs=s3fs.S3FileSystem(anon=False) # initialize the file system\n",
    "\n",
    "s3_url='s3://amazon-sagemaker- # location of the file in s3 bucket\n",
    "\n",
    "data=pd.read_csv(s3_url)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852347f0-338f-4084-8858-ad1e598b2e2a",
   "metadata": {},
   "source": [
    "**Code cell 2**: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0d78471-5dba-437d-a848-459a95481bd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:52:54.040717Z",
     "iopub.status.busy": "2025-03-06T00:52:54.039804Z",
     "iopub.status.idle": "2025-03-06T00:52:54.093243Z",
     "shell.execute_reply": "2025-03-06T00:52:54.092083Z",
     "shell.execute_reply.started": "2025-03-06T00:52:54.040654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "                                                text Sentiment_Label\n",
      "0  The customer service here is garbage. Tried pl...        Negative\n",
      "1  I can only offer three stars due to the loud t...        Negative\n",
      "2  We got the Plantano y Fritos y Frijoles and th...        Negative\n",
      "3  Restaurants these days have lowered their stan...        Positive\n",
      "4  Came here for their Fat Tuesday/Mardi Gras cel...        Positive\n"
     ]
    }
   ],
   "source": [
    "# Filter positive and negative reviews\n",
    "positive_reviews = data[data['Sentiment'] == 1].sample(n=50, random_state=42)\n",
    "negative_reviews = data[data['Sentiment'] == 0].sample(n=50, random_state=42)\n",
    "\n",
    "# Combine them into a new dataset\n",
    "sampled_df = pd.concat([positive_reviews, negative_reviews])\n",
    "\n",
    "# Add a new column with labeled sentiment\n",
    "sampled_df['Sentiment_Label'] = sampled_df['Sentiment'].map({1: 'Positive', 0: 'Negative'})\n",
    "\n",
    "# Select only the 'text' and 'Sentiment_Label' columns\n",
    "sampled_df = sampled_df[['text', 'Sentiment_Label']]\n",
    "\n",
    "# Shuffle the dataset\n",
    "sampled_df = sampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the new dataset\n",
    "sampled_df.to_csv('sampled_reviews.csv', index=False)\n",
    "\n",
    "#checking the new dataset\n",
    "print(len(sampled_df))\n",
    "# Display the first few rows\n",
    "print(sampled_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "923911ad-174c-46a0-8585-88ffbec99191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:52:56.211714Z",
     "iopub.status.busy": "2025-03-06T00:52:56.211103Z",
     "iopub.status.idle": "2025-03-06T00:52:58.721478Z",
     "shell.execute_reply": "2025-03-06T00:52:58.720440Z",
     "shell.execute_reply.started": "2025-03-06T00:52:56.211688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Predicted Sentiment (From LLM)-----------------------\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "The sentiment of the given review is negative.\n",
      "\n",
      "The reviewer expresses dissatisfaction and frustration with several aspects of their\n",
      "\n",
      "---------------Actual Sentiment (From Dataset)----------------------\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# Creating a bedrock runtime client.\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\") \n",
    "\n",
    "# each model has a unique Model Identifier\n",
    "model_id='anthropic.claude-3-sonnet-20240229-v1:0' # no of tokens for input\n",
    "# import a data sample from the dataset and prompt the model to perform sentiment analysis.\n",
    "\n",
    "random_index=random.randint(0,100) # create a random index\n",
    "\n",
    "data_sample=sampled_df.iloc[random_index]# access a random sample from the dataset using random_index\n",
    "\n",
    "data_sample.head()\n",
    "\n",
    "# Sample data extraction\n",
    "review_d = sampled_df['text'].iloc[random.randint(0, len(sampled_df)-1)]  # Randomly select a review\n",
    "sentiment = sampled_df['Sentiment_Label'].iloc[random.randint(0, len(sampled_df)-1)]  # Actual sentiment label\n",
    "\n",
    "# Define the prompt to send to Claude for sentiment analysis\n",
    "prompt = f'''\n",
    "Perform sentiment analysis on the given review, only predict whether it is positive, neutral, or negative.\n",
    "{review_d}\n",
    "'''\n",
    "\n",
    "# Prepare the API request for Anthropic Claude\n",
    "native_request = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",  # Version of the Claude model\n",
    "    \"max_tokens\": 25,  # Max tokens for response\n",
    "    \"temperature\": 0.4,  # Set the creativity of the model\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": prompt}  # User message with the prompt\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert the request to JSON format\n",
    "request = json.dumps(native_request)\n",
    "\n",
    "# Invoke the model through the AWS Bedrock client\n",
    "response = client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "# Parse the model's response\n",
    "model_response = json.loads(response[\"body\"].read())  # Extract the response body\n",
    "prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\")  # Extract the predicted sentiment\n",
    "\n",
    "# Display the predicted and actual sentiment\n",
    "print(\"---------------Predicted Sentiment (From LLM)-----------------------\")\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "print(prediction)\n",
    "\n",
    "print(\"\\n---------------Actual Sentiment (From Dataset)----------------------\")\n",
    "print(\"---------------------------------------------------------------------\\n\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcde887-b96a-49cd-aba7-e79031333495",
   "metadata": {},
   "source": [
    "**Code cell 3**: Perform Sentiment Analysis Using Zero-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a16b091c-1b7a-4f79-b3ed-9c587102fc77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T02:27:11.520713Z",
     "iopub.status.busy": "2025-03-06T02:27:11.519911Z",
     "iopub.status.idle": "2025-03-06T02:27:51.827540Z",
     "shell.execute_reply": "2025-03-06T02:27:51.826849Z",
     "shell.execute_reply.started": "2025-03-06T02:27:11.520670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews in dataset: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Sentiments: 100%|██████████| 100/100 [00:40<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions recorded: 100\n",
      "Total actual sentiments recorded: 100\n",
      "Total reviews skipped: 0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        50\n",
      "    positive       0.94      0.96      0.95        50\n",
      "\n",
      "    accuracy                           0.95       100\n",
      "   macro avg       0.95      0.95      0.95       100\n",
      "weighted avg       0.95      0.95      0.95       100\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[48  2]\n",
      " [ 3 47]]\n",
      "\n",
      "Misclassified Reviews:\n",
      "Index: 8, Review: You have to know that you can't get the Bento Box after 4 pm. Very sad about this glitch. We came all the way from NW Tucson/Marana for it.\n",
      "Predicted: negative, Actual: positive\n",
      "\n",
      "Index: 16, Review: The flavor for the Pad Thai tastes plain, but I'm sure if you want some spice they would change it for you.\n",
      "Predicted: positive, Actual: negative\n",
      "\n",
      "Index: 17, Review: A very unique place, the inside is eclectic and very cozy and charming.  This is Louisiana food at its best.  The service was quite good and responsible.  We enjoyed the food very much, although some was a little Louisiana spicy.  Good eatings for cajun and Louisianan food.  We had Gumbo and it was exactly what you would expect, full bodied and a little spicy.  The catfish sandwich was delicious and HUGE.  A must try!\n",
      "Predicted: positive, Actual: negative\n",
      "\n",
      "Index: 56, Review: This place was ok. Service not very good but we can chalk that up to covid. No dine in. The weird part was it took them a while to bring out food that definitely wasn't fresh. The portions were good sized and the price was very reasonable. The egg rolls were tiny and terrible. The fortune cookies were the same factory made crap you can get anywhere. I got the orange chicken which was just some over cooked chicken with a ton of burning hot orange sauce on it. It was like they took over cooked chicken that was sitting around and poured boiling sauce over it instead of cooking it fresh. The fried rice was pretty good. I read the reviews before going there and was expecting a little better. I guess you could say their service can't be as good because of the virus but it really seemed more like they just don't care about the people.\n",
      "Predicted: negative, Actual: positive\n",
      "\n",
      "Index: 65, Review: The pork was five star! Service was speedy and informative. The brisket had good flavor but they were out of juicy brisket (we were there in the afternoon), the cut we got even still was very dry and not very warm. The sauces all were decent as were our accompaniments, I enjoyed the fact that they had both a spicy and an extra spicy sauce as well. M\n",
      "\n",
      "The ambiance inside was a little lacking, just feels a bit thrown together and incomplete, also there was no music playing and being only one of two tables in the place between lunch and dinner times, the silence was a bit awkward. Also, they have amazing space out front for plenty of tables and additional dining that they are not utilizing AT ALL! So many people are more comfortable outside than in when dining out given the current pandemic, it's a shame they are not leveraging that opportunity.\n",
      "\n",
      "All in all I really wanted to give more stars but they lost a point on the brisket and a point on the ambiance. I look forward to coming back and trying them again and may update my rating at that time.\n",
      "Predicted: positive, Actual: negative\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import re\n",
    "import json\n",
    "\n",
    "def predict_sentiment(sampled_df, model_id, client):\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    skipped_reviews = 0  # Counter for skipped reviews\n",
    "    misclassified_reviews = []  # List to store misclassified reviews\n",
    "\n",
    "    print(f\"Total reviews in dataset: {sampled_df.shape[0]}\")\n",
    "\n",
    "    # Loop through the DataFrame and perform sentiment prediction for each review\n",
    "    for index, row in tqdm(sampled_df.iterrows(), total=sampled_df.shape[0], desc=\"Predicting Sentiments\"):\n",
    "        review = row['text']\n",
    "        actual_sentiment = row['Sentiment_Label'].strip().lower()  # Ensure actual sentiment is lowercase\n",
    "        \n",
    "        # Skip rows where sentiment is not 'positive' or 'negative'\n",
    "        if actual_sentiment not in ['positive', 'negative']:\n",
    "            print(f\"Skipping index {index}: Sentiment '{actual_sentiment}' is not valid.\")\n",
    "            skipped_reviews += 1\n",
    "            continue  # Ensure this is inside the loop\n",
    "\n",
    "        # Improved prompt\n",
    "        prompt = f\"\"\"Please predict the sentiment of the following review using only 'positive' or 'negative' as your response.\n",
    "        \n",
    "        Review: {review}\n",
    "        \n",
    "        Your response should be only one word: 'positive' or 'negative'.\n",
    "        \"\"\"\n",
    "        \n",
    "        native_request = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 5,  # Reduce token limit to avoid long responses\n",
    "            \"temperature\": 0.3,  # Lower temperature for more deterministic output\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        request = json.dumps(native_request)\n",
    "\n",
    "        try:\n",
    "            # Send the request to the model and receive the response\n",
    "            response = client.invoke_model(modelId=model_id, body=request)\n",
    "            response_body = response[\"body\"].read()\n",
    "\n",
    "            if response_body:\n",
    "                model_response = json.loads(response_body)\n",
    "                \n",
    "                # Extract the sentiment prediction from the model response\n",
    "                raw_prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\").strip().lower()\n",
    "\n",
    "                # Use regex to extract 'positive' or 'negative' from response\n",
    "                match = re.search(r\"\\b(positive|negative)\\b\", raw_prediction)\n",
    "                prediction = match.group(1) if match else None\n",
    "\n",
    "                # If extraction fails, re-prompt the model with a stricter query\n",
    "                if not prediction:\n",
    "                    print(f\"Re-prompting for index {index}: Model response '{raw_prediction}' did not contain 'positive' or 'negative'.\")\n",
    "                    \n",
    "                    strict_prompt = f\"\"\"Please provide only one word: 'positive' or 'negative' for this review:\n",
    "                    \n",
    "                    Review: {review}\n",
    "                    \n",
    "                    Only reply with 'positive' or 'negative'. No additional text.\"\"\"\n",
    "                    \n",
    "                    native_request[\"messages\"][0][\"content\"] = strict_prompt  # Modify the prompt\n",
    "                    strict_request = json.dumps(native_request)\n",
    "\n",
    "                    response = client.invoke_model(modelId=model_id, body=strict_request)\n",
    "                    response_body = response[\"body\"].read()\n",
    "\n",
    "                    if response_body:\n",
    "                        model_response = json.loads(response_body)\n",
    "                        raw_prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\").strip().lower()\n",
    "                        match = re.search(r\"\\b(positive|negative)\\b\", raw_prediction)\n",
    "                        prediction = match.group(1) if match else None\n",
    "\n",
    "                # If re-prompting also fails, skip the review\n",
    "                if not prediction:\n",
    "                    print(f\"Skipping index {index}: Even after re-prompting, model response '{raw_prediction}' did not contain 'positive' or 'negative'.\")\n",
    "                    skipped_reviews += 1\n",
    "                    continue\n",
    "                \n",
    "                # Store valid predictions\n",
    "                predictions.append(prediction)\n",
    "                actual.append(actual_sentiment)\n",
    "\n",
    "                # If prediction doesn't match actual sentiment, add to misclassified list\n",
    "                if prediction != actual_sentiment:\n",
    "                    misclassified_reviews.append({\n",
    "                        'index': index,\n",
    "                        'review': review,\n",
    "                        'predicted_label': prediction,\n",
    "                        'actual_label': actual_sentiment\n",
    "                    })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model invocation at index {index}: {str(e)}\")\n",
    "            skipped_reviews += 1  # Track errors as skipped reviews\n",
    "\n",
    "    print(f\"Total predictions recorded: {len(predictions)}\")\n",
    "    print(f\"Total actual sentiments recorded: {len(actual)}\")\n",
    "    print(f\"Total reviews skipped: {skipped_reviews}\")\n",
    "\n",
    "    return predictions, actual, misclassified_reviews\n",
    "\n",
    "# Call the function to get predictions and actual labels\n",
    "predictions, actual, misclassified_reviews = predict_sentiment(sampled_df, model_id, client)\n",
    "\n",
    "# Now you can evaluate the predictions using classification metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(actual, predictions))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(actual, predictions, labels=['positive', 'negative'])\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Print out the misclassified reviews\n",
    "print(\"\\nMisclassified Reviews:\")\n",
    "for review in misclassified_reviews:\n",
    "    print(f\"Index: {review['index']}, Review: {review['review']}\")\n",
    "    print(f\"Predicted: {review['predicted_label']}, Actual: {review['actual_label']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b4a16-e1d0-4266-8882-17eac9abc09f",
   "metadata": {},
   "source": [
    "**Code Cell 4** - Perform Sentiment Analysis Using Few-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d27612c5-e4ce-436f-8438-50367717837d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T02:32:34.992901Z",
     "iopub.status.busy": "2025-03-06T02:32:34.992447Z",
     "iopub.status.idle": "2025-03-06T02:33:23.593550Z",
     "shell.execute_reply": "2025-03-06T02:33:23.592805Z",
     "shell.execute_reply.started": "2025-03-06T02:32:34.992870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews in dataset: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total predictions recorded: 100\n",
      "Total actual sentiments recorded: 100\n",
      "Total skipped rows: 0\n",
      "Total missing predictions at indices: []\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        50\n",
      "    positive       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[47  3]\n",
      " [ 3 47]]\n",
      "\n",
      "Misclassified Reviews:\n",
      "Index: 8, Review: You have to know that you can't get the Bento Box after 4 pm. Very sad about this glitch. We came all the way from NW Tucson/Marana for it., Actual: positive, Predicted: negative\n",
      "Index: 17, Review: A very unique place, the inside is eclectic and very cozy and charming.  This is Louisiana food at its best.  The service was quite good and responsible.  We enjoyed the food very much, although some was a little Louisiana spicy.  Good eatings for cajun and Louisianan food.  We had Gumbo and it was exactly what you would expect, full bodied and a little spicy.  The catfish sandwich was delicious and HUGE.  A must try!, Actual: negative, Predicted: positive\n",
      "Index: 35, Review: I was staying at a resort so we got door dash they were pretty fast and food was still warm. The pizza was delicious loved that they used big pepperoni slices. Everything was great but I was super disappointed in the salad or I would have given a 5 star . It was just blah and the lemon dressing just tasted like olive oil, Actual: positive, Predicted: negative\n",
      "Index: 56, Review: This place was ok. Service not very good but we can chalk that up to covid. No dine in. The weird part was it took them a while to bring out food that definitely wasn't fresh. The portions were good sized and the price was very reasonable. The egg rolls were tiny and terrible. The fortune cookies were the same factory made crap you can get anywhere. I got the orange chicken which was just some over cooked chicken with a ton of burning hot orange sauce on it. It was like they took over cooked chicken that was sitting around and poured boiling sauce over it instead of cooking it fresh. The fried rice was pretty good. I read the reviews before going there and was expecting a little better. I guess you could say their service can't be as good because of the virus but it really seemed more like they just don't care about the people., Actual: positive, Predicted: negative\n",
      "Index: 65, Review: The pork was five star! Service was speedy and informative. The brisket had good flavor but they were out of juicy brisket (we were there in the afternoon), the cut we got even still was very dry and not very warm. The sauces all were decent as were our accompaniments, I enjoyed the fact that they had both a spicy and an extra spicy sauce as well. M\n",
      "\n",
      "The ambiance inside was a little lacking, just feels a bit thrown together and incomplete, also there was no music playing and being only one of two tables in the place between lunch and dinner times, the silence was a bit awkward. Also, they have amazing space out front for plenty of tables and additional dining that they are not utilizing AT ALL! So many people are more comfortable outside than in when dining out given the current pandemic, it's a shame they are not leveraging that opportunity.\n",
      "\n",
      "All in all I really wanted to give more stars but they lost a point on the brisket and a point on the ambiance. I look forward to coming back and trying them again and may update my rating at that time., Actual: negative, Predicted: positive\n",
      "Index: 79, Review: Went in this morning, 9:30am, to grab breakfast burrito. A woman approached me asking to help. I requested a breakfast burrito & since were out asked if she could make one. All the fixings are right there. But she said they don't do that. After she walked away someone else asked if I was being helped so I repeated my request. She, Paula Tellez, was happy to. As she handed it to me I asked if they were allowed to do this. She said yes and that she was there to make the customer happy. Thank you Paula. You are the kind of customer service person that makes AJ's shine. Also corporate was in the store & in spite of that the first person couldn't have been bothered. I have a love/hate relationship with AJ's., Actual: negative, Predicted: positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_n_shot_prompt(n_shot_pos_reviews, n_shot_neg_reviews):\n",
    "    prompt = (\n",
    "        \"Classify the sentiment of the review strictly as either 'positive' or 'negative'.\\n\"\n",
    "        \"1. A positive review expresses satisfaction, approval, or favorable experiences.\\n\"\n",
    "        \"2. A negative review expresses dissatisfaction, disapproval, or unfavorable experiences.\\n\"\n",
    "        \"You are only allowed to output 'positive' or 'negative'. No extra explanation or information.\\n\"\n",
    "        f\"Example 1:\\nReview: {n_shot_pos_reviews[0]}\\nSentiment: positive\\n\\n\"\n",
    "        f\"Example 2:\\nReview: {n_shot_pos_reviews[1]}\\nSentiment: positive\\n\\n\"\n",
    "        f\"Example 3:\\nReview: {n_shot_neg_reviews[0]}\\nSentiment: negative\\n\\n\"\n",
    "        f\"Example 4:\\nReview: {n_shot_neg_reviews[1]}\\nSentiment: negative\\n\\n\"\n",
    "        \"Now, classify the sentiment of the following review:\\n\"\n",
    "        \"Review: {{review}}\\n\"\n",
    "        \"Sentiment: \"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def predict_sentiment_with_n_shot(sampled_df, model_id, client):\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    skipped_rows = 0\n",
    "    missing_predictions = []\n",
    "    misclassified_reviews = []\n",
    "\n",
    "    print(f\"Total reviews in dataset: {sampled_df.shape[0]}\")\n",
    "\n",
    "    # Randomly sample 2 positive and 2 negative reviews\n",
    "    pos_reviews = sampled_df[sampled_df['Sentiment_Label'].str.lower() == 'positive'].sample(2, random_state=42)['text'].tolist()\n",
    "    neg_reviews = sampled_df[sampled_df['Sentiment_Label'].str.lower() == 'negative'].sample(2, random_state=42)['text'].tolist()\n",
    "\n",
    "    # Get the N-shot prompt with the selected reviews\n",
    "    prompt = get_n_shot_prompt(pos_reviews, neg_reviews)\n",
    "\n",
    "    # Loop through the DataFrame and perform sentiment prediction for each review\n",
    "    for index, row in tqdm(sampled_df.iterrows(), total=sampled_df.shape[0], desc=\"Predicting Sentiments\", leave=False):\n",
    "        review = row.get('text', '').strip()  # Handle missing review text gracefully\n",
    "        actual_sentiment = row.get('Sentiment_Label', '').strip().lower()  # Handle missing sentiment label gracefully\n",
    "\n",
    "        # Skip rows with missing review text or sentiment label\n",
    "        if not review or not actual_sentiment or actual_sentiment not in ['positive', 'negative']:\n",
    "            skipped_rows += 1\n",
    "            continue\n",
    "        \n",
    "        # Format the N-shot prompt for the current review\n",
    "        review_prompt = prompt.replace(\"{{review}}\", review)\n",
    "        \n",
    "        native_request = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",  # Specify the version of the model\n",
    "            \"max_tokens\": 20,  # Limit the number of tokens in the response\n",
    "            \"temperature\": 0.4,  # Set the temperature (creativity level)\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": review_prompt}  # Provide the prompt to the model\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Convert request to JSON\n",
    "        request = json.dumps(native_request)\n",
    "        \n",
    "        try:\n",
    "            # Send the request to the model and receive the response\n",
    "            response = client.invoke_model(modelId=model_id, body=request)\n",
    "            \n",
    "            # Parse the response body\n",
    "            response_body = response[\"body\"].read()\n",
    "            if response_body:\n",
    "                model_response = json.loads(response_body)\n",
    "\n",
    "                # Extract the sentiment prediction from the model response\n",
    "                raw_prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\").strip().lower()\n",
    "\n",
    "                # Use regex to extract only 'positive' or 'negative' if extra text is present\n",
    "                match = re.search(r\"\\b(positive|negative)\\b\", raw_prediction)\n",
    "                prediction = match.group(1) if match else None\n",
    "                \n",
    "                # Store valid predictions only\n",
    "                if prediction in ['positive', 'negative']:\n",
    "                    predictions.append(prediction)\n",
    "                    actual.append(actual_sentiment)\n",
    "\n",
    "                    # Identify misclassified reviews\n",
    "                    if prediction != actual_sentiment:\n",
    "                        misclassified_reviews.append({\n",
    "                            'index': index,\n",
    "                            'review': review,\n",
    "                            'actual': actual_sentiment,\n",
    "                            'predicted': prediction\n",
    "                        })\n",
    "                else:\n",
    "                    missing_predictions.append(index)  # Log the index of rows with invalid predictions\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model invocation at index {index}: {str(e)}\")\n",
    "    \n",
    "    # Report results\n",
    "    print(f\"\\nTotal predictions recorded: {len(predictions)}\")\n",
    "    print(f\"Total actual sentiments recorded: {len(actual)}\")\n",
    "    print(f\"Total skipped rows: {skipped_rows}\")\n",
    "    print(f\"Total missing predictions at indices: {missing_predictions}\\n\")\n",
    "\n",
    "    return predictions, actual, misclassified_reviews\n",
    "\n",
    "# Call the function to get predictions and actual labels\n",
    "predictions, actual, misclassified_reviews = predict_sentiment_with_n_shot(sampled_df, model_id, client)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(actual, predictions))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(actual, predictions, labels=['positive', 'negative'])\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Print misclassified reviews\n",
    "print(\"\\nMisclassified Reviews:\")\n",
    "for misclassified in misclassified_reviews:\n",
    "    print(f\"Index: {misclassified['index']}, Review: {misclassified['review']}, Actual: {misclassified['actual']}, Predicted: {misclassified['predicted']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef91301-1cd5-44fc-b0e8-a94e05976111",
   "metadata": {},
   "source": [
    "**Code cell 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a98feb68-8d23-4304-8344-3c7ef9ee350a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T01:57:51.526002Z",
     "iopub.status.busy": "2025-03-06T01:57:51.524646Z",
     "iopub.status.idle": "2025-03-06T01:57:51.531390Z",
     "shell.execute_reply": "2025-03-06T01:57:51.530461Z",
     "shell.execute_reply.started": "2025-03-06T01:57:51.525969Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_id_1='anthropic.claude-3-sonnet-20240229-v1:0' # LLM1\n",
    "\n",
    "model_id_2='meta.llama3-70b-instruct-v1:0' # LLM2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61d94455-55d6-4d84-9a69-73b7cc99ea6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T01:59:53.000491Z",
     "iopub.status.busy": "2025-03-06T01:59:52.999783Z",
     "iopub.status.idle": "2025-03-06T01:59:53.009786Z",
     "shell.execute_reply": "2025-03-06T01:59:53.009119Z",
     "shell.execute_reply.started": "2025-03-06T01:59:53.000460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text               We have been going to this place since it open...\n",
       "Sentiment_Label                                             positive\n",
       "Name: 33, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_index=random.randint(1,100) # create a random index\n",
    "\n",
    "data_sample=sampled_df.iloc[random_index] # access a random sample from the dataset using random_index\n",
    "\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5a61db5-f58b-4633-9d94-3a7acf149a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T02:00:38.928055Z",
     "iopub.status.busy": "2025-03-06T02:00:38.927787Z",
     "iopub.status.idle": "2025-03-06T02:00:38.939195Z",
     "shell.execute_reply": "2025-03-06T02:00:38.933098Z",
     "shell.execute_reply.started": "2025-03-06T02:00:38.928032Z"
    }
   },
   "outputs": [],
   "source": [
    "review=data_sample['text']\n",
    "\n",
    "sentiment=data_sample['Sentiment_Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f52ec-e34a-4aa8-8352-bc2958e305b5",
   "metadata": {},
   "source": [
    "LLM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c47e7615-c450-4e40-8cc2-7364c1ee87fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T02:00:45.802562Z",
     "iopub.status.busy": "2025-03-06T02:00:45.801619Z",
     "iopub.status.idle": "2025-03-06T02:00:47.724965Z",
     "shell.execute_reply": "2025-03-06T02:00:47.724002Z",
     "shell.execute_reply.started": "2025-03-06T02:00:45.802532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the review:\n",
      "\n",
      "The review is very positive about the restaurant. The reviewer has been going there since it opened and has always had excellent food and service. They highly recommend the Wildcat burger and the \"NelsonLove\" appetizer plate as a main course, describing it as fantastic. The reviewer encourages others to visit this restaurant.\n"
     ]
    }
   ],
   "source": [
    "prompt=f'''\n",
    "        Review: {review}\n",
    "        \n",
    "        summarize the given review.\n",
    "        \n",
    "        '''\n",
    "\n",
    "\n",
    "native_request = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 100,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "}\n",
    "request = json.dumps(native_request)  # convert the request into a json request\n",
    "\n",
    "response= client.invoke_model(modelId=model_id_1,body=request) # passing the json request and calling the model\n",
    "\n",
    "# the next two lines of code include parsing the model's response\n",
    "\n",
    "model_response= json.loads(response[\"body\"].read()) \n",
    "\n",
    "prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\") \n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2150c3f-530b-42db-bb5b-d8f07b00ff8d",
   "metadata": {},
   "source": [
    "LLM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14aa84ba-4a88-45eb-b92c-06d87f225437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T02:01:02.030312Z",
     "iopub.status.busy": "2025-03-06T02:01:02.029734Z",
     "iopub.status.idle": "2025-03-06T02:01:03.619495Z",
     "shell.execute_reply": "2025-03-06T02:01:03.618711Z",
     "shell.execute_reply.started": "2025-03-06T02:01:02.030284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_header_id|><|start_header_id|>\n",
      "\n",
      "Based on the summary, here are the things the reviewer likes and dislikes:\n",
      "\n",
      "**Likes:**\n",
      "\n",
      "* The restaurant in general\n",
      "* The food at the restaurant\n",
      "* The service at the restaurant\n",
      "* The Wildcat burger\n",
      "* The \"NelsonLove\" appetizer plate as a main course\n",
      "\n",
      "**Dislikes:**\n",
      "\n",
      "* None mentioned\n"
     ]
    }
   ],
   "source": [
    "prompt=f'''\n",
    "        Summary : {prediction}\n",
    "        Now from the summary, list the things the reviewer likes and dislikes\n",
    "        '''\n",
    "\n",
    "# Note that, the syntax here for Llama differs from that of Claude\n",
    "formatted_prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|> \"\"\"\n",
    "native_request = {\n",
    "    \"prompt\": formatted_prompt,\n",
    "    \"max_gen_len\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "}\n",
    "request = json.dumps(native_request) # converting into json request\n",
    "\n",
    "response = client.invoke_model(modelId=model_id_2, body=request) # invoking the model\n",
    "\n",
    "# parsing the model's response\n",
    "\n",
    "model_response = json.loads(response[\"body\"].read())  \n",
    "\n",
    "output = model_response.get(\"generation\", \"\")   # Note that, LLaMA (Meta) Response Formats here differs from that of Claude (Anthropic)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe1370-91c1-4be1-b362-d7bf7c327c6b",
   "metadata": {},
   "source": [
    "**Text cell 6**\n",
    "\n",
    "1. Comparing the performance for zero shot and few-shot learning\n",
    "\n",
    "With the existing sentiment label 0 for negative and 1 for positive in the available dataset, the zero-shot learning model achieved an accuracy of 95%, with a high precision of 0.96 and recall of 0.94 for negative reviews, and 0.94 precision and 0.96 recall for positive reviews. The confusion matrix for zero-shot showed 48 true positives, 2 false positives, 3 false negatives, and 47 true negatives, indicating a well-balanced model performance.\n",
    "\n",
    "On the other hand, the few-shot learning model, trained with 2 positive and 2 negative examples, achieved a slightly lower accuracy of 93%. Its precision for negative reviews was 0.92, and recall was 0.94, while for positive reviews, precision was 0.94 and recall was 0.92. The confusion matrix showed 46 true positives, 4 false positives, 3 false negatives, and 47 true negatives. While it performed well, it introduced more false positives and slightly lower recall for positive reviews compared to zero-shot learning, indicating a trade-off in performance due to the additional training examples.\n",
    "\n",
    "2. Assess where LLM predictions differ from actual label                                                         \n",
    "                                                                                                                 Zero-shot Prompting:\n",
    "\n",
    "Based on the results from code cell 3  \n",
    "\n",
    "False Positives (FP): The model incorrectly predicted positive sentiment for 2 reviews that were actually negative.\n",
    "\n",
    "False Negatives (FN): The model incorrectly predicted negative sentiment for 3 reviews that were actually positive.\n",
    "\n",
    "n-shot Prompting:\n",
    "\n",
    "Based on the results from code cell 4           \n",
    "\n",
    "False Positives (FP): The model incorrectly predicted positive sentiment for 4 reviews that were actually negative.\n",
    "\n",
    "False Negatives (FN): The model incorrectly predicted negative sentiment for 3 reviews that were actually positive \n",
    "                                                                                                                 \n",
    "\n",
    "3. Analyze potential reasons for misclassifications\n",
    "\n",
    "zero shot prompting\n",
    "\n",
    "Based on the misclassified reviews above from code cell 3, the misclassifications occurred due to mixed sentiments in reviews, where both positive and negative aspects were present. The model also struggled with context, negations, and subtle language nuances. In some cases, it focused too much on specific features, misinterpreting the overall sentiment.                                                                                                                                                                                          n-\n",
    "\n",
    "n shot prompting                                                                                                 \n",
    "                                                              \n",
    "Based on the misclassified reviews from code cell 4, the misclassifications occurred due to mixed sentiments in the reviews, where positive aspects were overshadowed by dissatisfaction in certain areas. For example, reviews with complaints about service or food quality were misclassified as negative despite praising other elements like the ambiance or specific dishes. The model struggled to balance the positive and negative sentiments, leading to errors in classification. Additionally, complex reviews with both praise and critique likely caused confusion in determining the overall sentiment. \n",
    "\n",
    "Both the model missclassified reviews with index, 8 and 17.\n",
    "   \n",
    "4. Differences in outputs from various LLMs\n",
    "\n",
    "Claude provides a narrative summary of the review, highlighting the positive sentiment, specific recommendations, and the reviewer’s loyalty to the restaurant. Lama, on the other hand, presents the review in a structured, bullet-point format, focusing on what the reviewer liked without adding extra context or emotions. Claude's output is more detailed and conversational, while Lama’s is straightforward and factual.                                                                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d1beeb-aa41-4119-b82a-892100bdf638",
   "metadata": {},
   "source": [
    "**Text cell 7**: Acknowledgement\n",
    "\n",
    "> Used Chatgpt\n",
    "    \n",
    "> Referred modules code, Sentiment-Analysis_with_prompting_techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc31b3-da77-4135-9d15-07212dc3bbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
